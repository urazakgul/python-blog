[
  {
    "objectID": "posts/post_7/index.html",
    "href": "posts/post_7/index.html",
    "title": "Reddit Başlıklarının Duygu Analizi: r/worldnews Örneği",
    "section": "",
    "text": "Reddit platformundan verileri çekebilmek için öncelikle buradan bir uygulama oluşturarak OAuth2 anahtarlarını almamız gerekiyor ki API’a ulaşabilelim.\nAdım 1. are you a developer? create an app... butonuna tıklayalım.\nAdım 2. name alanına kullanıcı ismimizi yazalım, script’i seçelim ve redirect uri alanına http://localhost:8080 bilgisini girelim.\nAdım 3. create app butonuna tıklayalım.\nBize verilen personal use script ve secret bilgilerini kullanacağız.\n\nKullanılacak Kütüphaneler\n\nimport pandas as pd\nimport datetime as dt\nimport praw\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nimport matplotlib.pyplot as plt\n\nSubreddit Başlıklarının Çekilmesi\npraw kütüphanesini kullanarak Reddit API’ına erişim sağlıyoruz.\n\nreddit = praw.Reddit(\n    client_id='personel_use_script',\n    client_secret='secret',\n    user_agent='username'\n)\n\ntopics_dict isimli bir sözlük oluşturalım. Bu sözlük çekmek istediğimiz bilgileri içerecek.\n\ntopics_dict = {\n    'id':[],\n    'title':[],\n    'score':[],\n    'comms_num':[], # kullanmayacağız ama kalsın\n    'created':[]\n}\n\nVerileri r/worldnews isimli subreddit’ten çekeceğiz ve sözlüğü veri çerçevesine dönüştüreceğiz.\n\nfor submission in reddit.subreddit('worldnews').new(limit=None):\n    topics_dict['id'].append(submission.id)\n    topics_dict['title'].append(submission.title)\n    topics_dict['score'].append(submission.score)\n    topics_dict['comms_num'].append(submission.num_comments)\n    topics_dict['created'].append(submission.created)\n\ntopics_df = pd.DataFrame(topics_dict)\n\n\nTarih ve saat bilgisi timestamp formatındaki created kolonunda yer almaktadır. Bunu datetime formatına dönüştürmemiz gerekiyor.\n\ndef timestamp_to_datetime(created):\n    return dt.datetime.fromtimestamp(created)\n\ntopics_df['datetime'] = topics_df['created'].apply(timestamp_to_datetime)\n\n\nDuygu Skorlarının Elde Edilmesi ve Verilerin Görselleştirilmesi\n\nsia = SIA()\nresults = []\n\nfor datetime, line, score in zip(topics_df['datetime'], topics_df['title'], topics_df['score']):\n    pol_score = sia.polarity_scores(line)\n    pol_score['datetime'] = datetime\n    pol_score['headline'] = line\n    pol_score['score'] = score\n    results.append(pol_score)\n\nresults_df = pd.DataFrame.from_records(results)\n\n\nYukarıda, öncelikle SIA (SentimentIntensityAnalyzer) isimli duygu analizi aracını kullanabilmek için bir nesne oluşturduk. Sonrasında her bir başlığın duygu analizini yapmak için SIA’in polarity_scores metodunu kullandık. Bu metot, bir metnin duygusal içeriğini analiz eder ve dört farklı duygu ölçüsü verir: pos (olumlu), neg (olumsuz), neu (nötr) ve compound (bileşik, tüm duyguların birleşimi). Biz compound ile ilgileneceğiz. Tüm bilgileri daha önce boş bir liste olarak oluşturduğumuz results değişkenine gönderdik ve döngü bittikten sonra results listesini results_df isimli veri çerçevesine dönüştürdük.\nGörselleştirmeyi iki farklı şekilde yapabiliriz.\nBirincisi, Reddit skorları (beğeni) ile duygu skorlarını gösterebiliriz. Şu an gündemde olduğu için başlıklarda geçen Iran veya Israel için farklı bir renk tercih edebiliriz.\n\nplt.figure(figsize=(10,6))\nplt.scatter(results_df['compound'], results_df['score'], alpha=.1, color='gray', label='Other Headlines')\nfor index, row in results_df.iterrows():\n    if 'Iran' in row['headline'] or 'Israel' in row['headline']:\n        plt.scatter(row['compound'], row['score'], color='red')\nplt.xlabel('Compound Sentiment Score')\nplt.ylabel('Reddit Score')\nplt.title('r/worldnews: Sentiment Score vs. Reddit Score')\nplt.grid(True)\nplt.yscale('log')\nplt.legend(['Other Headlines', 'Headlines containing Iran or Israel'])\nplt.show()\n\n\nİkincisi, duygu skorlarının ortalamada nasıl değiştiğini bir zaman serisi olarak gösterebiliriz.\n\nresults_df['date'] = results_df['datetime'].dt.date\ndaily_avg_compound = results_df.groupby('date')['compound'].mean()\n\nplt.figure(figsize=(10,6))\nplt.plot(daily_avg_compound.index, daily_avg_compound, marker='o', markersize=8, color='r')\nplt.ylabel('Daily Average Compound Score')\nplt.title('r/worldnews: Daily Average Compound Score over Time')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "posts/post_5/index.html",
    "href": "posts/post_5/index.html",
    "title": "Partilere Göre Milletvekillerinin Ortalama Yüzü: Türkiye Örneği",
    "section": "",
    "text": "1800’lü yıllarda Francis Galton, belirli bir grup insanda ortak olan yüz özelliklerini görselleştirmek amacıyla birçok farklı bireyin yüz fotoğraflarını tek bir fotoğraf filmi üzerine yansıtmış ve bu yüzlerin kompozit görüntülerini oluşturmuştur.\nBugün benzer bir yaklaşım, belirli bir grup insanın -örneğin, milletvekilleri gibi- ortak yüz özelliklerini incelemek amacıyla modern tekniklerle gerçekleştirilebilir.\nBu uygulamada, 28. dönem AKP, CHP, DEM ve MHP milletvekillerinin fotoğraflarını kullanarak parti ve cinsiyet kategorisinde ortalama bir yüz yaratacağız. Uygulamayı GitHub’ta bulunan şu repo yardımı ile yapacağız. Uygulamanın veri seti olan fotoğraflara ise burada bulunan tbmm_28 isimli klasör ile ulaşabilirsiniz.\nÖncelikle repoyu proje klasörümüze klonlayalım.\n\ngit clone https://github.com/johnwmillr/facer.git Facer\n\nKlonlama işleminden sonra bulunduğumuz dizinde sadece Facer klasöründeki facer klasörünü bırakabiliriz. facer klasörünün içinde ise facer.py ve utils.py dosyaları kalabilir.\nYukarıdaki işlemden sonra aşağıdaki gibi zip’li dosyayı indirip unzip’liyor ve dosyayı bulunduğumuz dizinde açtığımız model isimli klasöre taşıyoruz.\n\ncurl -O http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\nbunzip2 shape_predictor_68_face_landmarks.dat.bz2\n\nmkdir model\nmv shape_predictor_68_face_landmarks.dat model\n\nTBMM’nin web sitesinden alınan görseller .jpe formatında olduğu için facer klasöründe bulunan facer.py dosyasındaki glob_image_files() fonksiyonuna .jpe uzantısını ekliyoruz.\nOrtalama bir yüze ulaşmak için uygulanan adımlar burada detaylı bir şekilde veriliyor.\n\nfrom facer.facer import load_images, detect_face_landmarks, create_average_face\nimport matplotlib.pyplot as plt\nimport os\n\nfolders = [\n    './tbmm_28/akp/kadin',\n    './tbmm_28/chp/kadin',\n    './tbmm_28/dem/kadin',\n    './tbmm_28/mhp/kadin',\n    './tbmm_28/akp/erkek',\n    './tbmm_28/chp/erkek',\n    './tbmm_28/dem/erkek',\n    './tbmm_28/mhp/erkek'\n]\n\nfor folder in folders:\n    images = load_images(folder)\n\n    landmarks, faces = detect_face_landmarks(images)\n    average_face = create_average_face(faces, landmarks, save_image=False)\n\n    gender = 'kadin' if 'kadin' in folder else 'erkek'\n    party = folder.split('/')[2]\n    file_name = f'{party}_{gender}.jpg'\n\n    plt.imshow(average_face)\n    plt.axis('off')\n    plt.savefig(os.path.join('imgs', file_name))\n    plt.show()"
  },
  {
    "objectID": "posts/post_3/index.html",
    "href": "posts/post_3/index.html",
    "title": "Anlık Veri Akışı ile Oy Öngörüsü",
    "section": "",
    "text": "Seçim öngörüleri için seçim anketlerini kullanabilir veya seçim sonucuna etkisi olan değişkenler ile modelleme yapabiliriz. Modellemeye seçim anketleri de dahil edilebilir pek tabi.\nYukarıdaki iki yönteme ek olarak, seçim akşamı gelen veri akışı da hangi adayın/partinin ne kadarlık bir oy alacağı noktasında öngörüde bulunmamıza yardımcı olabilir. Bu yöntem, diğer yöntemlere göre daha kısa vadelidir. Çünkü veriler seçim akşamı alınabilmektedir. Amacı ise daha akışın başında hem oy oranlarının gidişatını kontrol edebilmek hem de öngörüde bulunabilmektir. Peki, bu yöntemde başarılı bir öngörü nasıl olur? Bunu üç kritere bağlıyorum: Gerçek sonuca yakın, istikrarlı güncellemeye sahip ve öngörüsü olabildiğince erkenden yapılan. Nedenlerini açıklayayım.\n\nÖngörümüzün gerçek sonuca yakın olmasını isteriz. Gerçekten uzak bir öngörü kimseyi tatmin etmez.\nModel güncellenebilir ancak güncellenen modelin güven de vermesi gerekir. Oynaklık seviyesi yüksek bir güncelleme modele olan güveni düşürecektir.\nGerçeğe yakın bir öngörü veri akışının başında da yapılabilir sonunda da. Veri akışının başında yapılan gerçeğe yakın öngörü daha anlamlı olacaktır.\n\nYapacağımız uygulamada İstanbul ilini ve Anadolu Ajansı verilerini baz alacağız. Verileri 31 Mart 2024 akşamı izlediğim NOW kanalından aldım. Veri seti, açılan sandık oranı ve adayların oy oranları ile aralarındaki farkları içermektedir. aa_20240331_istanbul isimli JSON verisine buradan ulaşabilirsiniz.\nKullanılacak Kütüphaneler\n\nimport json\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import shapiro\nimport statsmodels.stats.diagnostic as dg\nimport matplotlib.pyplot as plt\n\nAçılan Sandık Oranlarına Göre Adayların Oy Oranları ve Aralarındaki Farklar\n\nwith open('aa_20240331_istanbul.json', 'r', encoding='utf-8') as file:\n    data = json.load(file)\n\ndf = pd.DataFrame(data['Data'])\n\nprint(df.head())\n\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(\n    df['Açılan Sandık Oranı'],\n    df['Ekrem İmamoğlu'],\n    label='Ekrem İmamoğlu',\n    color='red',\n    linewidth=3\n)\nplt.plot(\n    df['Açılan Sandık Oranı'],\n    df['Murat Kurum'],\n    label='Murat Kurum',\n    color='orange',\n    linewidth=3\n)\nplt.xlabel('Açılan Sandık Oranı')\nplt.ylabel('Oy Oranı')\nplt.title('31 Mart 2024 Yerel Seçim - İstanbul')\nplt.text(\n    0.97,\n    -0.14,\n    'NOW kanalından alınan Anadolu Ajansı verileridir.',\n    color='gray',\n    fontsize=8,\n    fontstyle='italic',\n    ha='right',\n    transform=plt.gca().transAxes\n)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nAnadolu Ajansı geçmiş seçimlerde, gözlemlediğimiz üzere, veri akışını AKP ve ittifak ortaklarının adayları lehine başlatmıştır. 31 Mart 2024 yerel seçimlerinde ise CHP’nin adayı Ekrem İmamoğlu lehine başlamıştır. Anadolu Ajansı’nın geçmiş veri akışlarını göz önüne aldığımızda, bu başlangıç hem Ekrem İmamoğlu’nun seçimi kazanacağını hem de rakibi Murat Kurum’a fark atacağını göstermekteydi. Nitekim 11.55 puanlık fark ile öyle de oldu.\n\nplt.figure(figsize=(10, 6))\nplt.plot(\n    df['Açılan Sandık Oranı'],\n    df['Fark'],\n    color='blue',\n    linewidth=3\n)\nplt.xlabel('Açılan Sandık Oranı')\nplt.ylabel('Oy Oranı Farkı')\nplt.title('31 Mart 2024 Yerel Seçim - İstanbul')\nplt.text(\n    0.97,\n    -0.14,\n    'NOW kanalından alınan Anadolu Ajansı verileridir.\\nPozitif fark Ekrem İmamoğlu lehinedir.',\n    color='gray',\n    fontsize=8,\n    fontstyle='italic',\n    ha='right',\n    transform=plt.gca().transAxes\n)\nplt.grid(True)\nplt.show()\n\n\nModelin Geliştirilmesi\nVeri setimizde bulunan gözlem sayısı 50’dir ancak biz tamamını kullanmayacağız. Öngörülerimizi olabildiğince erken yapmalıyız. Bunun için açılan sandık oranının aşağı yukarı %50 olmasını bekleyebiliriz. Bu da 20 adet gözlem sayısına denk gelecektir. Oldukça küçük fakat kullanılamaz değil.\nÖngörü için regresyon modellerini kullanacağız.\n\ndependent_variable='Ekrem İmamoğlu'\nindependent_variable='Açılan Sandık Oranı'\nballot_box_rate=50\n\nmain_df = df[df[independent_variable] &lt;= ballot_box_rate][[independent_variable, dependent_variable]]\n\nRegresyon modelinde dependent_variable Ekrem İmamoğlu, independent_variable Açılan Sandık Oranı olacak. Burada Ekrem İmamoğlu oylarının açılan sandık oranlarına bağımlı olduğunu varsayıyoruz.\nBaşlamadan önce Ekrem İmamoğlu’nun oy grafiğini görelim.\n\nplt.figure(figsize=(10, 6))\nplt.plot(\n    df[independent_variable],\n    df[dependent_variable],\n    color='red',\n    linewidth=3\n)\nplt.axvline(x=main_df[independent_variable].iloc[-1], color='black', linestyle='--')\nplt.xlabel(f'{independent_variable}')\nplt.ylabel(f'{dependent_variable}')\nplt.title('31 Mart 2024 Yerel Seçim - İstanbul')\nplt.text(\n    0.97,\n    -0.14,\n    'NOW kanalından alınan Anadolu Ajansı verileridir.',\n    color='gray',\n    fontsize=8,\n    fontstyle='italic',\n    ha='right',\n    transform=plt.gca().transAxes\n)\nplt.grid(True)\nplt.show()\n\n\nGrafikte X ekseninde dikey bir çizgi bulunmaktadır. Bu çizginin sol tarafını kullanacak ve sağ tarafını hiç görmediğimizi varsayacağız.\nHer iki değişkenin de doğrusal olduğu regresyon modelini kurarak başlayalım.\n\ny = main_df[dependent_variable]\nX = main_df[independent_variable]\nX = sm.add_constant(X)\n\nmodel_linlin = sm.OLS(y, X).fit()\n\nprint(model_linlin.summary())\n\nTahminleri güven aralığı değerleri ile alalım.\n\nalpha=0.05\n\npredictions = model_linlin.get_prediction(X).summary_frame(alpha)\npredictions_mean = predictions['mean']\npredictions_lower = predictions['mean_ci_lower']\npredictions_upper = predictions['mean_ci_upper']\n\nHata terimlerini alalım.\n\nresiduals = model_linlin.resid\n\n\nSıfıra oldukça yakın p değerlerine sahip const kesme terimi ve Açılan Sandık Oranı değişkeni katsayılarının istatistiksel olarak anlamlı olduğunu söyleyebiliriz. Ayrıca, yaklaşık olarak %82’lik bir \\(R^2\\) yakaladık ki 0-1 ya da 0-100 aralığında değer aldığını düşünürsek bu iyi bir orandır. Regresyon modelindeki Açılan Sandık Oranı değişkeni sıfır olduğunda Ekrem İmamoğlu’nun oy oranı %49.3 olmaktadır. Buna ek olarak, Açılan Sandık Oranı değişkenindeki 1 puanlık artış Ekrem İmamoğlu oyunu ortalamada 0.0164 puan artırmaktadır.\n%95 güven aralığında gerçek ve tahmin edilen değerleri görelim.\n\nplt.figure(figsize=(10,6))\nplt.plot(X.iloc[:, 1], y, color='red', label='Gerçek')\nplt.plot(X.iloc[:, 1], predictions_mean, color='blue', label='Tahmin Edilen')\nplt.fill_between(X.iloc[:, 1], predictions_lower, predictions_upper, color='gray', alpha=0.3, label=f'%{100-alpha*100} Güven Aralığı')\nplt.xlabel(f'{independent_variable}')\nplt.ylabel(f'{dependent_variable}')\nplt.title('Lin-Lin Model')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nModelimiz fena durmasa da varsayımları sağlayıp sağlamadığına bakalım.\nHata terimleri normal dağılmaktadır.\n\nsw_statistic, sw_p_value = shapiro(residuals)\nif sw_p_value &gt;= alpha:\n    print('Hata terimleri normal dağılıyor.')\nelse:\n    print('Hata terimleri normal dağılmıyor.')\n\nHata terimlerinde otokorelasyon bulunmamaktadır.\n\nbg_test_statistic, bg_p_value, _, _ = dg.acorr_breusch_godfrey(model_linlin, nlags=5)\nif bg_p_value &gt;= alpha:\n    print('Hata terimleri arasında otokorelasyon yoktur.')\nelse:\n    print('Hata terimleri arasında otokorelasyon vardır.')\n\nModelde, alpha değerini 0.01 aldığımızda değişen varyans bulunmamaktadır.\n\nbp_test_statistic, bp_p_value, _, _ = dg.het_breuschpagan(residuals, model_linlin.model.exog)\n\nif bp_p_value &lt;= 0.01: # alpha\n    print('Modelde değişen varyans vardır.')\nelse:\n    print('Modelde değişen varyans yoktur.')\n\nEkrem imamoğlu için oy öngörüsünde bulunalım.\n\nX_value = [1, 100]\n\nforecasts = model_linlin.get_prediction(X_value).summary_frame(alpha)\nforecasted_vote_mean = forecasts['mean']\nforecasted_vote_lower = forecasts['obs_ci_lower']\nforecasted_vote_upper = forecasts['obs_ci_upper']\nprint(f'Oy Öngörüsü: %{forecasted_vote_mean.item():.2f}\\nOy Öngörüsü Aralığı: %{forecasted_vote_lower.item():.2f} - %{forecasted_vote_upper.item():.2f}')\n\n%50.57 - %51.32 öngörü aralığında %50.95’lik bir oy öngörüsünde bulunabiliriz. Gerçek oy oranı %51.14’tür. Öngörü, gerçek oyun yaklaşık 0.19 puan kadar altında kalmıştır ancak fena olmadığını söyleyebiliriz. Bu öngörüyü açılan sandık oranı %49 iken yaptık.\nSonraki seçimlerde pratik bir şekilde kullanmak için buraya kadar yaptığımız modelleme işlemlerini bir fonksiyona dönüştürelim.\n\ndef modeling_and_forecasting(df, dependent_variable, independent_variable, ballot_box_rate=50, alphas=(0.01, 0.05, 0.1)):\n    main_df = df[df[independent_variable] &lt;= ballot_box_rate][[independent_variable, dependent_variable]]\n\n    y = main_df[dependent_variable]\n    X = main_df[independent_variable]\n    X = sm.add_constant(X)\n\n    model_linlin = sm.OLS(y, X).fit()\n\n    print(model_linlin.summary())\n\n    predictions = [model_linlin.get_prediction(X).summary_frame(alpha) for alpha in alphas]\n    predictions_mean = [pred['mean'] for pred in predictions]\n    predictions_lower = [pred['mean_ci_lower'] for pred in predictions]\n    predictions_upper = [pred['mean_ci_upper'] for pred in predictions]\n\n    residuals = model_linlin.resid\n\n    sw_statistic, sw_p_value = shapiro(residuals)\n    h_normal = ['Hata terimleri normal dağılıyor.' if sw_p_value &gt;= alpha else 'Hata terimleri normal dağılmıyor.' for alpha in alphas]\n\n    bg_test_statistic, bg_p_value, _, _ = dg.acorr_breusch_godfrey(model_linlin, nlags=5)\n    h_autocorrelation = ['Hata terimleri arasında otokorelasyon yoktur.' if bg_p_value &gt;= alpha else 'Hata terimleri arasında otokorelasyon vardır.' for alpha in alphas]\n\n    bp_test_statistic, bp_p_value, _, _ = dg.het_breuschpagan(residuals, model_linlin.model.exog)\n    h_heteroscedasticity = ['Modelde değişen varyans vardır.' if bp_p_value &lt;= alpha else 'Modelde değişen varyans yoktur.' for alpha in alphas]\n\n    assumptions_table = {\n        'Alfa': alphas,\n        'Hata Terimleri Normalliği': h_normal,\n        'Otokorelasyon': h_autocorrelation,\n        'Değişen varyans': h_heteroscedasticity\n    }\n\n    assumptions_table_df = pd.DataFrame(assumptions_table)\n\n    X_value = [1, 100]\n\n    forecasts = [model_linlin.get_prediction(X_value).summary_frame(alpha) for alpha in alphas]\n    forecasted_vote_mean = [forecast['mean'].item() for forecast in forecasts]\n    forecasted_vote_lower = [forecast['obs_ci_lower'].item() for forecast in forecasts]\n    forecasted_vote_upper = [forecast['obs_ci_upper'].item() for forecast in forecasts]\n\n    forecast_table = {\n        'Alfa': alphas,\n        'Oy Öngörüsü - Ortalama': forecasted_vote_mean,\n        'Oy Öngörüsü - Alt Sınır': forecasted_vote_lower,\n        'Oy Öngörüsü - Üst Sınır': forecasted_vote_upper\n    }\n\n    forecast_table_df = pd.DataFrame(forecast_table)\n\n    return assumptions_table_df, forecast_table_df\n\nassumptions_df, forecast_df = modeling_and_forecasting(\n    df,\n    dependent_variable='Ekrem İmamoğlu',\n    independent_variable='Açılan Sandık Oranı'\n)\n\n\n\nAçılan sandık oranı %60 olduğunda modeli kontrol etmeye başlayabiliriz. Bundan sonrasında %90’a kadar her yeni veri akışında modeli takip edeceğiz. Peki, nasıl?\nModelimizin bağımsız değişken tarafına kukla değişken ekleyeceğiz. Böylece modelde herhangi bir kırılım olup olmadığını inceleyeceğiz. Eğer kırılım varsa modeli kukla değişkenli kuracağız. Bunun yanında, RMSE (Root Mean Squared Error, Kök Ortalama Kare Hatası) değerlerini de hesaplayacağız.\n\\(\\mathrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\\)\n\n# Aşağıda pas geçilen varsayımlar bir önceki fonksiyonda olduğu gibi eklenebilir.\n\ndef update_modeling_and_forecasting(df, ballot_box_rate, alpha=0.1):\n\n    updated_df = df[df['Açılan Sandık Oranı'] &lt;= ballot_box_rate][['Açılan Sandık Oranı', 'Ekrem İmamoğlu']]\n\n    updated_df['Dummy'] = [0 if i &lt; 20 else 1 for i in range(len(updated_df))]\n\n    y = updated_df['Ekrem İmamoğlu']\n    X = updated_df[['Açılan Sandık Oranı','Dummy']]\n    X = sm.add_constant(X)\n\n    model_linlin = sm.OLS(y, X).fit()\n\n    dummy_p_value = model_linlin.pvalues['Dummy']\n    if dummy_p_value &lt;= alpha:\n        X_value = [1, 100, 1]\n        dummy_significance = 'Modele Dahil Edildi'\n    else:\n        X = X.drop(columns=['Dummy'])\n        model_linlin = sm.OLS(y, X).fit()\n        X_value = [1, 100]\n        dummy_significance = 'Modele Dahil Edilmedi'\n\n    forecasts = model_linlin.get_prediction(X_value).summary_frame(alpha)\n    forecasted_vote = forecasts['mean'].iloc[0]\n    forecasted_vote_lower = forecasts['obs_ci_lower'].iloc[0]\n    forecasted_vote_upper = forecasts['obs_ci_upper'].iloc[0]\n    rmse = np.sqrt(np.mean((y - model_linlin.predict(X))**2))\n\n    return forecasted_vote, forecasted_vote_lower, forecasted_vote_upper, dummy_significance, rmse\n\nmin_ballot_box_rate=60\nmax_ballot_box_rate=90\nballot_box_rate = df[(df['Açılan Sandık Oranı'] &gt;= min_ballot_box_rate) & (df['Açılan Sandık Oranı'] &lt;= max_ballot_box_rate)]['Açılan Sandık Oranı'].tolist()\n\nforecast_dfs = []\n\nfor turnout in ballot_box_rate:\n\n    forecasted_vote, forecasted_vote_lower, forecasted_vote_upper,  dummy_significance, rmse = update_modeling_and_forecasting(df, turnout)\n\n    forecast_df = pd.DataFrame({\n        'Açılan Sandık Oranı': [turnout],\n        'Oy Öngörüsü - Ortalama': [forecasted_vote],\n        'Oy Öngörüsü - Alt Sınır': [forecasted_vote_lower],\n        'Oy Öngörüsü - Üst Sınır': [forecasted_vote_upper],\n        'Kukla Değişken': [dummy_significance],\n        'RMSE': [rmse]\n    })\n\n    forecast_dfs.append(forecast_df)\n\nforecast_df = pd.concat(forecast_dfs, ignore_index=True)\n\nprint(forecast_df)\n\nAçılan sandık oranı %83.1 olduğunda istatistiksel olarak anlamlı bir kırılım yaşandığını görüyoruz. Bu noktada öngörülerimizi kukla değişkenli yapıyoruz. Açılan sandık oranı %60.4 iken 0.098 olan RMSE değerini açılan sandık oranı %83.1’e geldiğinde 0.076’ya düşürüyoruz. Bu model ile daha önce yapılan öngörüyü %50.84’e revize edebiliriz. Gerçek oy oranı %51.14’tür. Öngörü, gerçek oyun yaklaşık 0.3 puan kadar altında kalmıştır."
  },
  {
    "objectID": "posts/post_1/index.html",
    "href": "posts/post_1/index.html",
    "title": "Python Dünyama Hoş Geldin!",
    "section": "",
    "text": "Uygulamalı içerikler oluşturacağım bu blog, bana günlük, sana rehber olsun."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python Blog",
    "section": "",
    "text": "Reddit Başlıklarının Duygu Analizi: r/worldnews Örneği\n\n\n\n\n\n\nDuygu Analizi\n\n\n\n\n\n\n\n\n\nNisan 14, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nİstanbul İlçe Belediye Başkanlarının X (Twitter) Profillerindeki Duygu Dağılımı\n\n\n\n\n\n\nYüz\n\n\nDuygu Analizi\n\n\n\n\n\n\n\n\n\nNisan 13, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nPartilere Göre Milletvekillerinin Ortalama Yüzü: Türkiye Örneği\n\n\n\n\n\n\nYüz\n\n\n\n\n\n\n\n\n\nNisan 10, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nSeçim Verilerinin Türkiye Haritasında Görselleştirilmesi\n\n\n\n\n\n\nHarita\n\n\nSeçim\n\n\n\n\n\n\n\n\n\nNisan 8, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nAnlık Veri Akışı ile Oy Öngörüsü\n\n\n\n\n\n\nEkonometri\n\n\nSeçim\n\n\n\n\n\n\n\n\n\nNisan 7, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nKorelasyon Tahmin Oyunu\n\n\n\n\n\n\nOyun\n\n\nWeb Uygulaması\n\n\n\n\n\n\n\n\n\nMart 24, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\n\n\n\n\n\n\nPython Dünyama Hoş Geldin!\n\n\n\n\n\n\nDiğer\n\n\n\n\n\n\n\n\n\nMart 23, 2024\n\n\nUraz Akgül\n\n\n\n\n\n\nEşleşen öğe yok"
  },
  {
    "objectID": "posts/post_2/index.html",
    "href": "posts/post_2/index.html",
    "title": "Korelasyon Tahmin Oyunu",
    "section": "",
    "text": "Korelasyon tahmin oyunu yapımında nelere ihtiyacımız olabilir?\nBirincisi, iki adet rassal seri üretmeliyiz ve bu serileri üretirken korelasyon katsayısını dikkate almalıyız. Buradaki korelasyon katsayısı Pearson’ı ifade etmektedir. Rassal serileri üretmek için numpy kütüphanesinin np.random.multivariate_normal fonksiyonundan faydalanabiliriz.\nİkincisi, kullanıcı için bir skorlama yapmalıyız. Bunun için RMSE (Root Mean Squared Error, Kök Ortalama Kare Hatası) metriğini kullanabiliriz. RMSE skoru düştükçe başarı artacaktır.\nÜçüncüsü, kullanıcı ile etkileşimde olmalıyız. Etkileşim için Streamlit ile bir web uygulaması yapabiliriz. Uygulamayı lokalde çalıştıracağız.\nKullanılacak Kütüphaneler\n\nimport streamlit as st\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nKorelasyonlu Rassal Serilerin Üretilmesi\n\ndef generate_correlated_data():\n    num_points = int(np.random.uniform(low=100, high=1000))\n    rho = round(np.random.uniform(low=-1, high=1), 2)\n    cov_matrix = np.array([[1, rho], [rho, 1]])\n    mu = [0, 0]\n    correlated_data = np.random.multivariate_normal(mean=mu, cov=cov_matrix, size=num_points)\n    return correlated_data, rho\n\nFonksiyonumuzun ismini generate_correlated_data olarak belirledik ve fonksiyonumuzun herhangi bir parametresi bulunmamaktadır.\nnum_points değişkeni, 100 ile 1000 arasında olmak üzere rassal olarak üretilecek serilere ait verilerin uzunluğunu temsil etmektedir. Bu değeri üretebilmek için numpy kütüphanesinin np.random.uniform fonksiyonunu kullandık ve int() ile değerin tam sayı veri tipinde olmasını sağladık.\nrho değişkeni, -1 ile 1 arasında rassal olarak olarak üretilmiş bir korelasyon katsayısını temsil etmektedir. Bu değeri üretebilmek için np.random.uniform fonksiyonunu kullandık. rho değerini noktadan sonra iki rakam gelecek şekilde ayarladık.\ncov_matrix değişkeni, 2x2’lik bir kovaryans matrisini temsil etmektedir.\nmu değişkeni, veri kümesinin her bir boyutu için belirlenen ortalama değeri temsil etmektedir. Bu değer 0 olacağı için X ve Y [0, 0]’dır.\ncorrelated_data değişkeni, np.random.multivariate_normal fonksiyonu yardımıyla üretilen verileri temsil etmektedir. Bu fonksiyon, çok değişkenli bir normal dağılımdan rassal örnekler üretir. Fonksiyonun içerisine parametre olarak ortalama, kovaryans matrisi ve örnek büyüklüğü girilir.\ngenerate_correlated_data fonksiyonu bize correlated_data ve rho değerlerini dönüyor. correlated_data değişkenindeki ilk seriye correlated_data[:,0]; ikinci seriye correlated_data[:,1] ile ulaşılabilir.\nFonksiyonun döndüğü değerleri kullanarak bir görselleştirme yapalım.\n\ncorrelated_data, rho = generate_correlated_data()\n\n# print(f'Randomly selected correlation: {rho}')\n\nplt.figure(figsize=(8, 6))\nplt.scatter(correlated_data[:,0], correlated_data[:,1], alpha=0.7)\nplt.title('Scatter Plot of Correlated Data')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True)\nplt.show()\n\n\nBir diğer fonksiyonumuz olan ve RMSE değerini hesaplayan calculate_rmse fonksiyonuna bakalım.\n\\(\\mathrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\\)\n\ndef calculate_rmse(predictions, actuals):\n    mse = np.mean((predictions - actuals) ** 2)\n    rmse = round(np.sqrt(mse), 4)\n    return rmse\n\ncalculate_rmse fonksiyonu, predictions ve actuals olmak üzere 2 adet parametre alıyor. Önce mse değişkenine tahminler ile gerçek değerler arasındaki farkların karelerinin ortalamasını gönderiyoruz. Ardından da bu ortalamanın karekökünü rmse değişkenine atıyoruz ve bu değeri noktadan sonra 4 rakam olacak şekilde döndürüyoruz.\nKodların ana yapısını oluşturduk.\nStreamlit Web Uygulamasının Yapımı\nWeb uygulaması tarafında kullanılan kodlar aşağıdadır.\n\n# Oturum durumu değişkenlerinin tanımlanması ve varsayılan değerlerin ayarlanması\nst.session_state.setdefault('rhos', []) # Korelasyon katsayıları\nst.session_state.setdefault('guesses', []) # Kullanıcının tahminleri\nst.session_state.setdefault('rmse_values', []) # RMSE değeri\nst.session_state.setdefault('plots', []) # Görseller\n\n# Korelasyonlu veri oluşturan fonksiyon\ndef generate_correlated_data():\n    num_points = int(np.random.uniform(low=100, high=1000))\n    rho = round(np.random.uniform(low=-1, high=1), 2)\n    cov_matrix = np.array([[1, rho], [rho, 1]])\n    mu = [0, 0]\n    correlated_data = np.random.multivariate_normal(mean=mu, cov=cov_matrix, size=num_points)\n    return correlated_data, rho\n\n# RMSE hesaplayan fonksiyon\ndef calculate_rmse(predictions, actuals):\n    mse = np.mean((predictions - actuals) ** 2)\n    rmse = round(np.sqrt(mse), 4)\n    return rmse\n\n# 'rhos' listesi boş ise yeni bir korelasyonlu veri oluşturulması ve korelasyon katsayısının kaydedilmesi\nif len(st.session_state['rhos']) == 0:\n    correlated_data, rho = generate_correlated_data()\n    st.session_state['rhos'].append(rho)\n\n# 'plots' listesi boşsa ilk görselin oluşturulması ve kaydedilmesi\nif len(st.session_state['plots']) == 0:\n    plt.figure(figsize=(8, 6))\n    plt.scatter(correlated_data[:,0], correlated_data[:,1], alpha=0.7)\n    plt.title('Scatter Plot of Correlated Data')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.grid(True)\n    st.session_state['plots'].append(plt)\n    st.pyplot(st.session_state['plots'][0])\n\n# Kullanıcının tahmini\nuser_guess = st.sidebar.text_input(\n    label='Your Guess:',\n    value='0.0'\n)\n\n# Kullanıcı tahmininin ondalık sayıya dönüştürülmesi\nuser_guess = float(user_guess)\n\n# Tahmin butonunun oluşturulması\nguess_button = st.sidebar.button(label='Guess')\n\n# Tahmin butonuna basıldığında yapılacaklar\nif guess_button:\n    correlated_data, rho = generate_correlated_data()\n    st.session_state['rhos'].append(rho)\n    st.session_state['guesses'].append(user_guess)\n    rmse = calculate_rmse(np.array(st.session_state['rhos'][:-1]), np.array(st.session_state['guesses']))\n    st.session_state['rmse_values'].append(rmse)\n\n    st.subheader(f'Guess: {st.session_state[\"guesses\"][-1]}, Actual: {st.session_state[\"rhos\"][-2]}, RMSE: {st.session_state[\"rmse_values\"][-1]}')\n\n    plt.figure(figsize=(8, 6))\n    plt.scatter(correlated_data[:,0], correlated_data[:,1], alpha=0.7)\n    plt.title('Scatter Plot of Correlated Data')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.grid(True)\n    st.session_state['plots'].append(plt)\n    st.pyplot(st.session_state['plots'][-1])\n\nWindows/Visual Studio Code için bir not: Streamlit uygulamasının yapımında kullanılacak olan kodları .py uzantılı app.py isminde bir script’e kaydedip terminalden streamlit run app.py komutu ile çalıştırabilirsiniz.\nGelecek içeriklerde görüşmek dileğiyle."
  },
  {
    "objectID": "posts/post_4/index.html",
    "href": "posts/post_4/index.html",
    "title": "Seçim Verilerinin Türkiye Haritasında Görselleştirilmesi",
    "section": "",
    "text": "31 Mart 2024 yerel seçimlerini geride bıraktık ancak biz Türkiye’de yaşayanlar için iki seçim arası kısa bir reklam arası gibi. Önümüzdeki seçimlere hazırlıklı olmak için bu arayı değerlendirmeye devam ediyoruz.\nBu uygulamada, CHP’nin iller bazında aldığı oyları harita üzerinde göstereceğiz. local_elections_province_20240331 isimli JSON dosyasında bulunan verilere buradan ulaşabilirsiniz.\nHarita üzerinde görselleştirme yapmak için geopandas kütüphanesini kullanacağız. geopandas, isminden de anlaşılacağı üzere, popüler veri bilimi kütüphanesi pandas’ı jeo-uzamsal veriler ile destekleyip genişletiyor.\nHaritada görselleştirmek için öncelikle Türkiye’nin .shp uzantılı dosyasını bulmamız gerekiyor. .shp, coğrafi verileri depolamak için kullanılan bir vektör veri formatıdır. Buradan turkey_administrativelevels0_1_2.zip isimli dosyayı indirebilirsiniz. Eğer bir problem ile karşılaşırsanız burada bulunan dosyayı da indirebilirsiniz.\nKullanılacak Kütüphaneler\n\nimport json\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nVerilerin Hazırlanması\nread_file() fonksiyonu ile .shp uzantılı dosyayı içeri aktaralım.\n\nshapefile_tr = gpd.read_file('turkey_administrativelevels0_1_2/tur_polbnda_adm1.shp')\n\nprint(shapefile_tr)\n\n\nshapefile_tr ile birleştireceğimiz seçim verilerinin yer aldığı JSON dosyasını içe aktaralım.\n\nwith open('local_elections_province_20240331.json', 'r', encoding='utf-8') as file:\n    data = json.load(file)\n\ndf = pd.DataFrame(data['Data'])\n\nprint(df)\n\n\nshapefile_tr tablosundaki adm1_tr sütunu ile df tablosundaki PROVINCE sütununu kullanarak iki tabloyu birleştireceğiz.\n\nmerged_df = pd.merge(\n  shapefile_tr,\n  df,\n  left_on='adm1_tr',\n  right_on='PROVINCE',\n  how='left'\n)\n\n\nBirleştirdikten sonra harita aşamasına geçebiliriz.\nHaritanın Oluşturulması\nHaritayı en temiz haliyle görelim.\n\nfig, ax = plt.subplots(figsize = (10,10))\nmerged_df.plot(ax=ax)\nplt.show()\n\n\nŞimdi verileri haritaya gönderelim ve görselin daha profesyonel görünmesini sağlayalım.\n\nfig, ax = plt.subplots(figsize = (10,10))\nmerged_df.plot(ax=ax, column='CHP', cmap='Reds')\nax.axis('off')\nax.set_title(\n    '31 Mart 2024 Yerel Seçimleri - Cumhuriyet Halk Partisi Oy Dağılımı',\n    fontdict = {'fontsize': 8}\n)\nax.text(\n    0.95,\n    0.01,\n    \"Veriler Yeni Şafak'ın web sitesinden alınmıştır.\",\n    color='gray',\n    fontsize=6,\n    fontstyle='italic',\n    ha='right',\n    va='bottom',\n    transform=ax.transAxes\n)\nplt.show()\n\n\nNeler yaptık? İnceleyelim.\nÖncelikle, plt.subplots() ile bir Figure ve Axes nesnesi oluşturuyoruz. Sonrasında, merged_df isimli DataFrame’den gelen verileri kullanarak harita oluşturuyoruz ve bu işlemi plot() ile gerçekleştiriyoruz. column parametresi haritada renk kodlaması yapılacak sütunu belirtirken, cmap parametresi renk haritasını belirler. Sadece haritanın görüntülenmesini sağlamak için ax.axis() ile eksenleri kapalı hale getiriyoruz. ax.set_title() ile haritanın başlığını ayarlıyoruz. Son olarak, ax.text() ile sağ alt köşeye bir metin ekliyoruz ve plt.show() ile grafiği görüntülüyoruz.\nYukarıda sürekli verileri kullandık. Peki, kategorik verileri harita üzerinde nasıl gösterebiliriz?\nCHP’nin %50’den az ve çok aldığı illeri görselleştirmek istediğimizi varsayalım.\n\nmerged_df['CHP_50'] = merged_df['CHP'].apply(\n  lambda x: '%50\\'den az' if x &lt; 50 else '%50\\'den çok'\n)\n\n\n\ncolors = {\n    \"%50'den az\": \"gray\",\n    \"%50'den çok\": \"black\"\n}\n\ncmap = ListedColormap(list(colors.values()))\n\nfig, ax = plt.subplots(figsize = (10,10))\nmerged_df.plot(\n  ax=ax,\n  column='CHP_50',\n  cmap=cmap,\n  legend=True,\n  legend_kwds={'loc': 'lower left', 'fontsize': 8}\n)\nax.axis('off')\nax.set_title(\n    \"31 Mart 2024 Yerel Seçimleri - Cumhuriyet Halk Partisi'nin %50'den Az ve Çok Aldığı İller\",\n    fontdict = {'fontsize': 8}\n)\nax.text(\n    0.95,\n    0.01,\n    \"Veriler Yeni Şafak'ın web sitesinden alınmıştır.\",\n    color='gray',\n    fontsize=6,\n    fontstyle='italic',\n    ha='right',\n    va='bottom',\n    transform=ax.transAxes\n)\nplt.show()\n\n\nFarklı neler yaptık? İnceleyelim.\ncolors isminde bir sözlük tanımladık. Bu sözlük, görselleştirmede kullanılacak renkleri ve bunlara karşılık gelen kategorileri içeriyor. Ayrıca, cmap isminde bir ListedColormap nesnesi oluşturduk. Bu, renk paletini belirtiyor ve colors sözlüğünden alınan renklerle oluşturuluyor. Önceki haritada olmayan, bu haritada sol alt köşede bulunan lejant ise kategorilerin tanımlarını içeriyor."
  },
  {
    "objectID": "posts/post_6/index.html",
    "href": "posts/post_6/index.html",
    "title": "İstanbul İlçe Belediye Başkanlarının X (Twitter) Profillerindeki Duygu Dağılımı",
    "section": "",
    "text": "Yapılan çalışmaların yanında içinde profil fotoğrafının da olduğu sosyal medya kullanımı da önemli olabiliyor.\nBu uygulamada, İstanbul ilçe belediye başkanlarının X (Twitter) profillerindeki duygularını inceleyeceğiz. Duyguların tespitinde Py-Feat kütüphanesinden faydalanacağız.\nKullanılacak Kütüphaneler\n\nimport os\nimport pandas as pd\nfrom feat import Detector\nfrom feat.plotting import imshow\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nFotoğrafların İçe Aktarılması\nBuradan ulaşabileceğiniz fotoğraflar ilçe belediye başkanlarının X (Twitter) hesaplarından indirilmiştir.\n\nimage_folder = 'ilce_bb_profil/'\nimage_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n\nDuyguların Tespit Edilmesi ve Görselleştirilmesi\nPy-Feat, görüntülerden ve videolardan yüz ifadelerini kolayca tespit etmek, yüz ifadesi verilerini önceden işlemek ve analiz etmek ve yüz ifadesi verilerini görselleştirmek için kapsamlı bir araç ve model seti sağlar. Py-Feat önceden eğitilmiş çeşitli modelleri içeriyor.\n\ndetector = Detector(\n    face_model='retinaface', # face detection\n    landmark_model='mobilefacenet', # facial landmark detection\n    facepose_model='img2pose', # facial pose estimation\n    au_model='xgb', # action unit detection\n    emotion_model='resmasknet', # emotion detection\n)\n\n\nYüz tespiti (Face detection, face_model): Bir görüntüdeki veya bir videodaki insan yüzlerini algılama sürecidir. Yüz tespiti, bir görüntü içindeki yüz bölgelerini belirlemek için kullanılır. Parametre seçenekleri şunlardır: retinaface, mtcnn, faceboxes, img2pose ve img2pose-c.\nYüz belirleme (Facial landmark detection, landmark_model): Yüzün belirli noktalarını (örneğin, gözler, burun, ağız) tespit etme sürecidir. Bu noktalar genellikle gözbebekleri, burun ucundaki nokta, dudakların kenarları gibi önemli anatomik yerlerdir. Parametre seçenekleri şunlardır: mobilefacenet, mobilenet ve pfld.\nYüz poz tahmini (Facial Pose estimation, facepose_model): Bir yüzün konumunu ve/veya dönüşünü belirleme sürecidir. Yüzün kaç derece eğik olduğunu, hangi yönde baktığını tahmin etmeyi içerir. Parametre seçenekleri şunlardır: img2pose ve img2pose-c.\nHareket Birimi tespiti (Action Unit detection, au_model): Yüz ifadelerindeki belirli kas gruplarını temsil eden hareket birimlerini (action units) tanımlama sürecidir. Örneğin, kaşların kaldırılması, dudakların büzülmesi gibi. Parametre seçenekleri şunlardır: xgb ve svm.\nDuygu tespiti (Emotion detection, emotion_model): Bir kişinin yüz ifadesinden duygusal durumunu belirleme sürecidir. Örneğin, mutlu, üzgün, kızgın gibi duyguları tanımlama. Parametre seçenekleri şunlardır: resmasknet ve svm.\n\nBir döngü ile tüm fotoğrafları dahil edeceğiz ama öncesinde örnek bir fotoğraf ile sürece bakalım.\n\nexample_img = 'uskudar_chp.jpg'\nimshow(image_folder + example_img)\n\n\ndetect_image() ile yüklenen modelleri kullanalım.\n\nsingle_face_prediction = detector.detect_image(image_folder + example_img)\n\n\nBuradan duyguları çekelim.\n\nemotions = single_face_prediction.emotions\n\n\nPy-Feat görselleştirme imkanı da sunuyor. Bunu iki farklı şekilde yapabiliriz.\n\nfigs = single_face_prediction.plot_detections(poses=True)\n\n\n\nfigs = single_face_prediction.plot_detections(faces='aus', muscles=True)\n\n\nTüm fotoğraflar için duyguları tespit edelim. Görseli ısı haritası ile yapacağız.\nÖncesinde image_files değişkenine tüm fotoğrafları aktarmıştık. Bunu kullanabiliriz.\n\nemotions_df = pd.DataFrame()\n\nfor image_file in image_files:\n    face_prediction = detector.detect_image(image_folder + image_file)\n    face_prediction_final = face_prediction[face_prediction['FaceScore'] == face_prediction['FaceScore'].max()]\n    emotions = face_prediction_final.emotions\n    ilce, parti = image_file.split('_')\n    parti = parti.split('.')[0]\n    emotions['image_file'] = ilce.upper() + '-' + parti.upper()\n    emotions_df = pd.concat([emotions_df, emotions], ignore_index=True)\n\nemotions_df = emotions_df.set_index('image_file')\nemotions_df.columns = emotions_df.columns.str.upper()\n\nDöngüde bulunan face_prediction_final değişkenini birden fazla yüz tespiti olduğu için oluşturdum. Büyükçekmece belediye başkanının profilinde kedi de bulunmaktadır.\n\nexample_img = 'buyukcekmece_chp.jpg'\nimshow(image_folder + example_img)\n\n\nIsı haritası ile duyguları gösterebiliriz.\n\nplt.figure(figsize=(10, 12))\nsns.heatmap(emotions_df, cmap='Reds', annot=False, linewidths=.5)\nplt.title('İstanbul İlçe Belediye Başkanları X (Twitter) Profilleri Duygu Dağılımı')\nplt.tick_params(left=False, bottom=False)\nplt.ylabel('')\nplt.show()\n\n\nProfil fotoğraflarında doğal olarak en güçlü duygunun happiness olduğunu görüyoruz. neutral pozlar da kendini göstermektedir."
  }
]