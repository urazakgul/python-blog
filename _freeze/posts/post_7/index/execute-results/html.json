{
  "hash": "c36c68250686b69673256370ca84afd9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Reddit Başlıklarının Duygu Analizi: r/worldnews Örneği\"\nauthor: \"Uraz Akgül\"\ndate: \"2024-04-14\"\n# date-modified: last-modified\ndate-format: \"MMMM D, YYYY\"\ncategories: [Duygu Analizi]\nimage: \"imgs/img_6.png\"\nexecute:\n  eval: false\n---\n\nReddit platformundan verileri çekebilmek için öncelikle [buradan](https://www.reddit.com/prefs/apps){.external target=\"_blank\"} bir uygulama oluşturarak OAuth2 anahtarlarını almamız gerekiyor ki API'a ulaşabilelim.\n\nAdım 1. `are you a developer? create an app...` butonuna tıklayalım.\n\nAdım 2. `name` alanına kullanıcı ismimizi yazalım, `script`'i seçelim ve `redirect uri` alanına `http://localhost:8080` bilgisini girelim.\n\nAdım 3. `create app` butonuna tıklayalım.\n\nBize verilen `personal use script` ve `secret` bilgilerini kullanacağız.\n\n![](imgs/img_1.PNG)\n\n**Kullanılacak Kütüphaneler**\n\n::: {#cdbffbb0 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport datetime as dt\nimport praw\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n**Subreddit Başlıklarının Çekilmesi**\n\n`praw` kütüphanesini kullanarak Reddit API'ına erişim sağlıyoruz.\n\n::: {#ba233455 .cell execution_count=2}\n``` {.python .cell-code}\nreddit = praw.Reddit(\n    client_id='personel_use_script',\n    client_secret='secret',\n    user_agent='username'\n)\n```\n:::\n\n\n`topics_dict` isimli bir sözlük oluşturalım. Bu sözlük çekmek istediğimiz bilgileri içerecek.\n\n::: {#63239a4f .cell execution_count=3}\n``` {.python .cell-code}\ntopics_dict = {\n    'id':[],\n    'title':[],\n    'score':[],\n    'comms_num':[], # kullanmayacağız ama kalsın\n    'created':[]\n}\n```\n:::\n\n\nVerileri `r/worldnews` isimli subreddit'ten çekeceğiz ve sözlüğü veri çerçevesine dönüştüreceğiz.\n\n::: {#eeba8ede .cell execution_count=4}\n``` {.python .cell-code}\nfor submission in reddit.subreddit('worldnews').new(limit=None):\n    topics_dict['id'].append(submission.id)\n    topics_dict['title'].append(submission.title)\n    topics_dict['score'].append(submission.score)\n    topics_dict['comms_num'].append(submission.num_comments)\n    topics_dict['created'].append(submission.created)\n\ntopics_df = pd.DataFrame(topics_dict)\n```\n:::\n\n\n![](imgs/img_2.PNG)\n\nTarih ve saat bilgisi timestamp formatındaki `created` kolonunda yer almaktadır. Bunu datetime formatına dönüştürmemiz gerekiyor.\n\n::: {#fae6ffb7 .cell execution_count=5}\n``` {.python .cell-code}\ndef timestamp_to_datetime(created):\n    return dt.datetime.fromtimestamp(created)\n\ntopics_df['datetime'] = topics_df['created'].apply(timestamp_to_datetime)\n```\n:::\n\n\n![](imgs/img_3.PNG)\n\n**Duygu Skorlarının Elde Edilmesi ve Verilerin Görselleştirilmesi**\n\n::: {#fcc8670a .cell execution_count=6}\n``` {.python .cell-code}\nsia = SIA()\nresults = []\n\nfor datetime, line, score in zip(topics_df['datetime'], topics_df['title'], topics_df['score']):\n    pol_score = sia.polarity_scores(line)\n    pol_score['datetime'] = datetime\n    pol_score['headline'] = line\n    pol_score['score'] = score\n    results.append(pol_score)\n\nresults_df = pd.DataFrame.from_records(results)\n```\n:::\n\n\n![](imgs/img_4.PNG)\n\nYukarıda, öncelikle `SIA` (SentimentIntensityAnalyzer) isimli duygu analizi aracını kullanabilmek için bir nesne oluşturduk. Sonrasında her bir başlığın duygu analizini yapmak için `SIA`'in `polarity_scores` metodunu kullandık. Bu metot, bir metnin duygusal içeriğini analiz eder ve dört farklı duygu ölçüsü verir: `pos` (olumlu), `neg` (olumsuz), `neu` (nötr) ve `compound` (bileşik, tüm duyguların birleşimi). Biz `compound` ile ilgileneceğiz. Tüm bilgileri daha önce boş bir liste olarak oluşturduğumuz `results` değişkenine gönderdik ve döngü bittikten sonra `results` listesini `results_df` isimli veri çerçevesine dönüştürdük.\n\nGörselleştirmeyi iki farklı şekilde yapabiliriz.\n\nBirincisi, Reddit skorları (beğeni) ile duygu skorlarını gösterebiliriz. Şu an gündemde olduğu için başlıklarda geçen Iran veya Israel için farklı bir renk tercih edebiliriz.\n\n::: {#163ab43a .cell execution_count=7}\n``` {.python .cell-code}\nplt.figure(figsize=(10,6))\nplt.scatter(results_df['compound'], results_df['score'], alpha=.1, color='gray', label='Other Headlines')\nfor index, row in results_df.iterrows():\n    if 'Iran' in row['headline'] or 'Israel' in row['headline']:\n        plt.scatter(row['compound'], row['score'], color='red')\nplt.xlabel('Compound Sentiment Score')\nplt.ylabel('Reddit Score')\nplt.title('r/worldnews: Sentiment Score vs. Reddit Score')\nplt.grid(True)\nplt.yscale('log')\nplt.legend(['Other Headlines', 'Headlines containing Iran or Israel'])\nplt.show()\n```\n:::\n\n\n![](imgs/img_5.png)\n\nİkincisi, duygu skorlarının ortalamada nasıl değiştiğini bir zaman serisi olarak gösterebiliriz.\n\n::: {#e98ea230 .cell execution_count=8}\n``` {.python .cell-code}\nresults_df['date'] = results_df['datetime'].dt.date\ndaily_avg_compound = results_df.groupby('date')['compound'].mean()\n\nplt.figure(figsize=(10,6))\nplt.plot(daily_avg_compound.index, daily_avg_compound, marker='o', markersize=8, color='r')\nplt.ylabel('Daily Average Compound Score')\nplt.title('r/worldnews: Daily Average Compound Score over Time')\nplt.grid(True)\nplt.show()\n```\n:::\n\n\n![](imgs/img_6.png)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}