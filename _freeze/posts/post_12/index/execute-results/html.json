{
  "hash": "8b99b3315df9cb00cdcd713b1e274064",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"TCMB'nin Faiz Oranlarına İlişkin Duyuru Metinlerinin İçerik Analizi\"\nauthor: \"Uraz Akgül\"\ndate: \"2024-05-04\"\n# date-modified: last-modified\ndate-format: \"MMMM D, YYYY\"\ncategories: [Metin Analizi, Duygu Analizi, Merkez Bankası]\nimage: \"imgs/img_6.png\"\nexecute:\n  eval: false\n---\n\nFaiz kararları sadece sayılardan ibaret değildir. Türkiye Cumhuriyet Merkez Bankası'nın (TCMB) faiz oranlarına ilişkin basın duyuruları da büyük bir öneme sahiptir. Bu duyurular, TCMB'nin kararlarını destekleyen veya açıklayan bir metin içerir ve bu metin, ekonomi uzmanları, yatırımcılar ve piyasa analistleri için kritik bir kaynaktır. Basın duyuruları temelde, TCMB'nin ekonomik göstergeleri nasıl yorumladığını ve gelecekteki politika eğilimlerini nasıl değerlendirdiğini içerir.\n\nVeri seti, Erdem Başçı ve Yaşar Fatih Karahan arası dönemlerde yayınlanan 148 adet İngilizce duyuru metnini kapsamaktadır. Son veri 2024 yılının Nisan ayına aittir. `cbrt_press_releases` isimli veri setine [buradan](https://github.com/urazakgul/python-blog/tree/main/posts/post_12){.external target=\"_blank\"} ulaşabilirsiniz.\n\n**Kullanılacak Kütüphaneler**\n\n::: {#d6c6632c .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport string\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nfrom transformers import pipeline\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nplt.style.use('fivethirtyeight')\n```\n:::\n\n\n**Veri Setinin İçe Aktarılması ve Bazı Ayarların Yapılması**\n\n::: {#400b8516 .cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_excel('cbrt_press_releases.xlsx')\n\ndf['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\ndf = df.sort_values(by='Date')\ndf = df.set_index('Date')\n```\n:::\n\n\n![](imgs/img_1.PNG)\n\n**Metin İçeriğinin Analizi**\n\nMetin analizinde `NLTK` kütüphanesini kullanacağız. `NLTK` (Natural Language Toolkit), doğal dil işleme (NLP) görevlerini gerçekleştirmek için kullanılan bir kütüphanedir.\n\nAşağıdaki gerekli olan indirme işlemlerini yapalım.\n\n::: {#30aae9bd .cell execution_count=3}\n``` {.python .cell-code}\nnltk.download('punkt')\nnltk.download('stopwords')\n```\n:::\n\n\n`punkt`, cümlelerin ve kelimelerin tokenize (parçalama) edilmesi için kullanılan bir veri modelidir. Tokenization, metni daha küçük parçalara ayırma işlemidir ve doğal dil işleme uygulamalarında sıkça kullanılır.\n\n`stopwords`, dilin yapısı gereği sıklıkla karşılaşılan ve genellikle metin analizi veya doğal dil işleme uygulamalarında önemsiz olarak kabul edilen kelimelerdir.\n\n*Tarihlere ve başkanlara göre kelime sayıları*\n\nKelimeleri sayacak `word_counter` isimli ve `text` parametresi bulunan bir fonksiyon yazalım.\n\n::: {#c6b6de8b .cell execution_count=4}\n``` {.python .cell-code}\ndef word_counter(text):\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = text.translate(str.maketrans('', '', '\\n\\xa0'))\n    text = text.lower()\n    tokens = word_tokenize(text)\n    return len(tokens)\n```\n:::\n\n\nYukarıda ilk olarak, metindeki noktalama işaretlerini (`string.punctuation` ile tanımlı olanlar) kaldırıyoruz. Bu, metindeki noktalama işaretlerinin (virgül, nokta, ünlem işareti vb.) kelime sayısını etkilememesini sağlıyor. Ardından, metindeki boşlukları ve diğer belirli karakterleri (newline karakteri `\\n` ve non-breaking space karakteri `\\xa0`) kaldırıyoruz. Bu, metindeki boşlukların kelime sayısını etkilememesini sağlıyor. Metni `lower()` ile küçük harfe dönüştürüyoruz. Bu, büyük ve küçük harflerin ayrımını kaldırarak aynı kelimenin farklı biçimlerini aynı olarak değerlendirmesini sağlıyor. Metni `word_tokenize()` ile kelime parçalarına ayırıyoruz (tokenize işlemi). Bu, metindeki her bir kelimeyi ayrı bir öğe olarak ele alarak bu öğelerin sayısını saymamızı sağlıyor. Son olarak, kelime listesinin uzunluğunu `len()` ile hesaplayarak bu değeri döndürüyoruz.\n\n::: {#04747c3f .cell execution_count=5}\n``` {.python .cell-code}\ndf['Word Count'] = df['Text'].apply(word_counter)\n\nnum_governors = len(df['Governor'].unique())\ncolors = cm.Set1(np.linspace(0, 1, num_governors))\nunique_governors = df['Governor'].unique()\n\nplt.figure(figsize=(12, 7))\nfor i, governor in enumerate(unique_governors):\n    data = df[df['Governor'] == governor]\n    plt.plot(data.index, data['Word Count'], label=governor, linestyle='-', color=colors[i])\n\nplt.title('Word Counts by Dates and Governors')\nplt.text(\n    0.99,\n    -0.1,\n    \"Based on CBRT's press releases on interest rates.\",\n    verticalalignment='bottom',\n    horizontalalignment='right',\n    transform=plt.gca().transAxes,\n    color='gray',\n    fontsize=10,\n    fontstyle='italic'\n)\nplt.grid(True)\nplt.legend(fontsize='small')\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nYukarıda ilk olarak, DataFrame'de bulunan `Text` sütunundaki her bir metin için `word_counter` fonksiyonunu çağırıyoruz ve her bir metnin kelime sayısı hesaplıyoruz. Görselde kullanmak için `num_governors` değişkenine başkan sayısını, `colors` değişkenine de bu başkan sayısı kadar renk atıyoruz. `unique_governors` ise daha sonra başkanları sırasıyla kullanacağımız için oluşturduğumuz bir değişken oluyor. Görseli oluştururken lejanttaki dönemlerine göre başkan sıralamasının önemini koruyoruz.\n\n![](imgs/img_2.png)\n\n*Başkanlara göre kelime bulutları*\n\n::: {#2c4f4da7 .cell execution_count=6}\n``` {.python .cell-code}\ngovernors_texts = df.groupby('Governor')['Text'].apply(' '.join)\n\nfig, axs = plt.subplots(7, 1, figsize=(16, 18))\nfor i, governor in enumerate(unique_governors, 1):\n    text = governors_texts[governor]\n    wordcloud = WordCloud(\n        background_color='white',\n        colormap='gray',\n        contour_color='black',\n        contour_width=1\n    ).generate(text)\n\n    axs[i-1].imshow(wordcloud, interpolation='bilinear')\n    axs[i-1].set_title(f'Word Cloud for Governor {governor}', fontsize=12)\n    axs[i-1].axis('off')\n\nplt.figtext(\n    0.99,\n    -0.3,\n    \"Based on CBRT's press releases on interest rates.\",\n    verticalalignment='bottom',\n    horizontalalignment='right',\n    transform=plt.gca().transAxes,\n    color='gray',\n    fontsize=9,\n    fontstyle='italic'\n)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\nYukarıda, `governors_texts` ile başkanların kendi dönemlerinde yayınlanan duyuru metinlerini bir araya getiriyoruz. Ardından, `WordCloud` nesnesi oluşturarak bir kelime bulutu oluşturma işlemini gerçekleştiriyoruz. Detaylı bakalım.\n\n`WordCloud` nesnesini oluştururken aşağıdaki parametreleri ve değerlerini kullandık.\n\n`background_color='white'`, kelime bulutunun arka plan rengini beyaz yapıyor. Yani, kelime bulutunun içindeki kelimeler beyaz bir arka plan üzerine yerleştiriliyor. `colormap='gray'`, kelime bulutunda kullanılacak renk haritasını gri tonlarda olacak şekilde ayarlıyor. Kelimelerin yoğunluklarına göre farklı gri tonları kullanılıyor. `contour_color='black'`, kelime bulutunun kenar çizgilerinin rengini siyah yapıyor. Bu, kelime bulutunu çevreleyen konturun siyah olacağı anlamına gelir. `contour_width=1`, kelime bulutunun kenar çizgilerinin kalınlığı 1 piksel olarak ayarlıyor. Bu, konturun ince olacağı anlamına gelir.\n\n`interpolation` parametresine atadığımız `bilinear` değeri, görüntüyü daha pürüzsüz bir şekilde yeniden örnekleme yaparak görüntülerken, kenarları daha yumuşak hale getiriyor.\n\n![](imgs/img_3.png)\n\n*Tarihlere göre metinlerdeki pozitif/negatif duygu değişimleri*\n\n`CentralBankRoBERTa`, bir LLM'dir (large language model veya büyük dil modeli).\n\n![](imgs/img_4.PNG)\n\n`CentralBankRoBERTa`, temelde beş temel makroekonomik aktörü ayıran bir ekonomik aktör sınıflandırıcısı ile merkez bankası iletişimlerindeki cümlelerin duygusal içeriğini belirleyen ikili bir duygu sınıflandırıcısını birleştirir. Bu, merkez bankası iletişimlerindeki cümlelerin duygusal tonunu ve ekonomik aktörleri tanımak için kullanılabilir.\n\nMimarisi aşağıdaki gibidir.\n\n![](imgs/img_5.PNG)\n\n`SentimentClassifier` modeli, verilen bir cümlenin hane halkları, işletmeler, finans sektörü veya hükümet için olumlu mu yoksa olumsuz mu olduğunu belirlemek amacıyla tasarlanmıştır. Bu model, RoBERTa mimarisine dayanır ve doğru tahminler sağlamak için çeşitli ve kapsamlı bir veri kümesinde ince ayarlanmıştır (fine-tuned). Bir merkez bankasının iletişimini analiz etmek için duygusal içerikle ilgili uygun bir doğal dil işleme yöntemini test etmek üzere yapılan çalışmada FED, ECB ve BIS'den toplam 13,458 önceden etiketlenmiş cümle örneği kullanılmıştır.\n\nPerformans metrikleri şöyledir: Accuracy: 88%, F1 Score: 0.88, Precision: 0.88 ve Recall: 0.88\n\n::: {#c987a078 .cell execution_count=7}\n``` {.python .cell-code}\nsentiment_classifier = pipeline(\n    'text-classification',\n    model='Moritz-Pfeifer/CentralBankRoBERTa-sentiment-classifier'\n)\n\ndef classify_sentences(text):\n    text = text.replace('\\n', '').replace('\\xa0', '')\n    sentences = text.split('. ')\n    sentences = [sentence + '.' if not sentence.endswith('.') else sentence for sentence in sentences]\n    positive_count = 0\n    negative_count = 0\n    for sentence in sentences:\n        sentiment_result = sentiment_classifier(sentence)\n        positive_count += sum(1 for item in sentiment_result if item['label'] == 'positive')\n        negative_count += sum(1 for item in sentiment_result if item['label'] == 'negative')\n    return positive_count, negative_count\n```\n:::\n\n\nYukarıda ilk olarak, `pipeline` fonksiyonunu çağırarak bir duygu sınıflandırma pipeline'ı oluşturuyoruz. Burada kullanılan model, Moritz Pfeifer tarafından oluşturulmuş `CentralBankRoBERTa` modelidir. Ardından, `classify_sentences()` fonksiyonunu tanımlıyoruz. Bu fonksiyon, bir metin alıyor ve metni cümlelere bölüyor. Metindeki `\\n` ve `\\xa0` gibi boşlukları kaldırmak için `replace()` kullanıyoruz. Metni bir nokta ve boşluk ile cümlelere bölüyoruz. Cümle nokta ile bitmiyorsa cümlenin sonunda bir nokta olmasını sağlıyoruz. Pozitif ve negatif duyguların sayısını tutmak için `positive_count` ve `negative_count` isminde iki değişken tanımlıyor ve sıfır değerini atıyoruz. Her cümle için döngü oluşturuyoruz ve `sentiment_classifier()` fonksiyonunu çağırarak cümlenin duygusu belirliyoruz. Bu işlem, cümlenin duygusunu tahmin etmek için önceden eğitilmiş modeli kullanıyor. Duygu sonuçlarına bakarak pozitif ve negatif etiket sayılarını hesaplıyoruz. `sentiment_result` içindeki her bir öğe için etiketinin `positive` veya `negative` olup olmadığını kontrol ediyor ve sonuca göre ilgili sayaçları artırıyoruz. Son olarak fonksiyonda toplam pozitif ve negatif etiket sayılarını döndürüyoruz.\n\nAşağıda ise `df`'te, `Positive Count` ve `Negative Count` sütunları oluşturuyoruz ve `classify_sentences()` isimli `text` parametreli fonksiyonu çalıştırıyoruz.\n\n::: {#b84c50db .cell execution_count=8}\n``` {.python .cell-code}\ndf['Positive Count'] = 0\ndf['Negative Count'] = 0\n\ndf[['Positive Count', 'Negative Count']] = df['Text'].apply(classify_sentences).apply(pd.Series)\n\nplt.figure(figsize=(12, 8))\nplt.plot(df.index, df['Positive Count'], label='Positive Count', color='blue')\nplt.plot(df.index, df['Negative Count'], label='Negative Count', color='red')\nplt.fill_between(df.index, df['Positive Count'], df['Negative Count'], color='gray', alpha=0.3)\nplt.title('Positive and Negative Sentiment Counts Over Time')\nplt.text(\n    0.99,\n    -0.1,\n    \"Based on CBRT's press releases on interest rates.\",\n    verticalalignment='bottom',\n    horizontalalignment='right',\n    transform=plt.gca().transAxes,\n    color='gray',\n    fontsize=10,\n    fontstyle='italic'\n)\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n![](imgs/img_6.png)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}